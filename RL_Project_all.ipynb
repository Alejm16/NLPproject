{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL-Project all.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOPAPczr4y2jl1JSPBwNIi4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alejm16/NLPproject/blob/main/RL_Project_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "l24y2PYSq5Hg",
        "outputId": "cc163dc8-50bf-45af-b753-fafeec90b6e8"
      },
      "source": [
        "!pip3 install --upgrade pandas==1.3.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas==1.3.1\n",
            "  Downloading pandas-1.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.1) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.1) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.1) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.1) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.1 which is incompatible.\u001b[0m\n",
            "Successfully installed pandas-1.3.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MrlB3Ocpea3",
        "outputId": "69a4eaf8-ce1b-4bfc-87b1-9be29a926449"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_pickle(\"/content/enron_dataframe.pkl\")\n",
        "print(df.head())\n",
        "print(df.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text    Person\n",
            "0                                                     arnold-j\n",
            "1                            let's push until monday  arnold-j\n",
            "2                                        what's pdx?  arnold-j\n",
            "3  BMO wants to do this sleave trade. Duke, Dyneg...  arnold-j\n",
            "4  I'm big seller of interventions. they tend not...  arnold-j\n",
            "(95573, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_PYWLtLrSaG"
      },
      "source": [
        "train/test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQmMz5-grR_3"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Person'], train_size=0.8, random_state = 237)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRoFCCsVtIn4"
      },
      "source": [
        "Preprocessing Input\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxivHLamsJoI"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "# 'binary' parameter when not set indicates the encoding measure is term frequency\n",
        "vectorizer = CountVectorizer()\n",
        "data_train = vectorizer.fit_transform(X_train)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "data_test = vectorizer.fit_transform(X_test)\n",
        "print(vectorizer.get_feature_names_out())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyYVQPwKs7QC",
        "outputId": "78852417-e7a5-46fd-ed6a-3fefe91b38de"
      },
      "source": [
        "## converting to numeric labels\n",
        "from sklearn import preprocessing\n",
        "tgt_enc = preprocessing.LabelEncoder()\n",
        "persons = np.unique(df['Person'])\n",
        "# fit your targets of the training data to the LabelEncoder instance\n",
        "tgt_enc.fit(persons)\n",
        "\n",
        "# get the set of unique classes\n",
        "print(f\"Unique categories: {list(tgt_enc.classes_)}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique categories: ['allen-p', 'arnold-j', 'arora-h', 'badeer-r', 'bailey-s', 'bass-e', 'baughman-d', 'beck-s', 'benson-r', 'blair-l', 'brawner-s', 'buy-r', 'campbell-l', 'carson-m', 'cash-m', 'causholli-m', 'corman-s', 'crandell-s', 'cuilla-m', 'dasovich-j', 'davis-d', 'dean-c', 'delainey-d', 'derrick-j', 'dickson-s', 'donoho-l', 'donohoe-t', 'dorland-c', 'ermis-f', 'farmer-d', 'fischer-m', 'forney-j', 'fossum-d', 'gang-l', 'gay-r', 'geaccone-t', 'germany-c', 'gilbertsmith-d', 'giron-d', 'griffith-j', 'grigsby-m', 'haedicke-m', 'hayslett-r', 'heard-m', 'hendrickson-s', 'hernandez-j', 'hodge-j', 'holst-k', 'horton-s', 'hyatt-k', 'hyvl-d', 'jones-t', 'kaminski-v', 'kean-s', 'keavey-p', 'keiser-k', 'king-j', 'kitchen-l', 'kuykendall-t', 'lavorato-j', 'lay-k', 'lenhart-m', 'lewis-a', 'lokay-m', 'lokey-t', 'love-p', 'lucci-p', 'maggi-m', 'mann-k', 'martin-t', 'may-l', 'mccarty-d', 'mcconnell-m', 'mckay-b', 'mckay-j', 'mclaughlin-e', 'meyers-a', 'mims-thurston-p', 'motley-m', 'neal-s', 'nemec-g', 'panus-s', 'parks-j', 'pereira-s', 'perlingiere-d', 'phanis-s', 'pimenov-v', 'platter-p', 'presto-k', 'quenet-j', 'quigley-d', 'rapp-b', 'reitmeyer-j', 'richey-c', 'ring-a', 'ring-r', 'rodrique-r', 'rogers-b', 'ruscitti-k', 'sager-e', 'saibi-e', 'salisbury-h', 'sanchez-m', 'sanders-r', 'scholtes-d', 'schoolcraft-d', 'schwieger-j', 'scott-s', 'semperger-c', 'shackleton-s', 'shankman-j', 'shapiro-r', 'shively-h', 'skilling-j', 'slinger-r', 'smith-m', 'solberg-g', 'south-s', 'staab-t', 'stclair-c', 'steffes-j', 'stepenovitch-j', 'storey-g', 'sturm-f', 'swerzbin-m', 'symes-k', 'taylor-m', 'tholt-j', 'thomas-p', 'townsend-j', 'tycholiz-b', 'ward-k', 'watson-k', 'weldon-c', 'whalley-g', 'whalley-l', 'white-s', 'whitt-m', 'williams-j', 'williams-w3', 'wolfe-j', 'ybarbo-p', 'zipper-a', 'zufferli-j']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb7oYLyxtRnY",
        "outputId": "0465ef8d-861a-452f-84b0-6b85bcd559e6"
      },
      "source": [
        "labels_persons = tgt_enc.transform(persons)\n",
        "print(f\"Unique categories: {labels_persons}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique categories: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8XQ1kaZtYOL"
      },
      "source": [
        "output_train_data = tgt_enc.transform(y_train)\n",
        "output_test_data = tgt_enc.transform(y_test)\n",
        "input_train_data = vectorizer.fit_transform(X_train)\n",
        "input_test_data = vectorizer.transform(X_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogJ6jgVgr0hT"
      },
      "source": [
        "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(input_train_data, output_train_data)\n",
        "rbf = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(input_train_data, output_train_data)\n",
        "poly = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(input_train_data, output_train_data)\n",
        "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(input_train_data, output_train_data)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXwJ-evXlLcf"
      },
      "source": [
        "Linear Kernel SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CFiQlqik3rh"
      },
      "source": [
        "linear_pred = linear.predict(input_test_data)\n",
        "accuracy_lin = lin.score(input_test_data, output_test_data)\n",
        "print(\"Accuracy Sigmoid Kernel:\", accuracy_lin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyFwy0XXlQ4g"
      },
      "source": [
        "Poly SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3pTjueAlPLH",
        "outputId": "5825fc2b-b4dd-4d0d-9996-12be76801ee0"
      },
      "source": [
        "poly_pred = poly.predict(input_test_data)\n",
        "accuracy_poly = poly.score(input_test_data, output_test_data)\n",
        "print(\"Accuracy Polynomial Kernel:\", accuracy_poly)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Polynomial Kernel: 0.0656552445723254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJV_c8xHTF0t"
      },
      "source": [
        "import pickle\n",
        "pkl_filename = \"/content/poly_svm.pkl\"\n",
        "with open(pkl_filename,'wb') as file:\n",
        "  pickle.dump(poly,file)"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}